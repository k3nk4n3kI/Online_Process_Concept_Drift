{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimized Dynamic Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Append the directory containing the src folder to sys.path\n",
    "sys.path.append('/Users/lars/Documents/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, set_seed\n",
    "from tensorflow.keras.callbacks import Callback # type: ignore\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from src.data.data_manager import data_loader\n",
    "from src.models.baseline_models import MetricsCallbackDynamic, BERTModelBuilderDynamic, sort_by_length, create_buckets_and_batches, create_buckets_and_batches_bert\n",
    "from src.visualization.evaluation import plot_loss_accuracy_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path variables for datasets\n",
    "directory = \"/Users/lars/Documents/Uni/Masterarbeit/Online_Process_Concept_Drift\"\n",
    "path_raw = \"/data/raw/\"\n",
    "path_interim = \"/data/interim/\"\n",
    "path_processed = \"/data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducability\n",
    "\n",
    "seed = 1234\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = data_loader(directory, path_interim, \"Long_Helpdesk_train\")\n",
    "val_tensor = data_loader(directory, path_interim, \"Long_Helpdesk_val\")\n",
    "test_tensor = data_loader(directory, path_interim, \"Helpdesk_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefix_Trace</th>\n",
       "      <th>Next_Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assign-seriousness</td>\n",
       "      <td>take-in-charge-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket</td>\n",
       "      <td>take-in-charge-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket take-...</td>\n",
       "      <td>resolve-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket take-...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket take-...</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13170</th>\n",
       "      <td>assign-seriousness</td>\n",
       "      <td>take-in-charge-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13172</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket wait</td>\n",
       "      <td>resolve-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13173</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket wait ...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket wait ...</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13175 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Prefix_Trace  \\\n",
       "0                                     assign-seriousness   \n",
       "1               assign-seriousness take-in-charge-ticket   \n",
       "2      assign-seriousness take-in-charge-ticket take-...   \n",
       "3      assign-seriousness take-in-charge-ticket take-...   \n",
       "4      assign-seriousness take-in-charge-ticket take-...   \n",
       "...                                                  ...   \n",
       "13170                                 assign-seriousness   \n",
       "13171           assign-seriousness take-in-charge-ticket   \n",
       "13172      assign-seriousness take-in-charge-ticket wait   \n",
       "13173  assign-seriousness take-in-charge-ticket wait ...   \n",
       "13174  assign-seriousness take-in-charge-ticket wait ...   \n",
       "\n",
       "               Next_Activity  \n",
       "0      take-in-charge-ticket  \n",
       "1      take-in-charge-ticket  \n",
       "2             resolve-ticket  \n",
       "3                     closed  \n",
       "4                        end  \n",
       "...                      ...  \n",
       "13170  take-in-charge-ticket  \n",
       "13171                   wait  \n",
       "13172         resolve-ticket  \n",
       "13173                 closed  \n",
       "13174                    end  \n",
       "\n",
       "[13175 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Checking for Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable for GPU memory management\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Enable mixed precision for better performance and reduced memory usage\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear any existing GPU memory state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reduce TensorFlow logging verbosity\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_classes = 10\n",
    "batch_size = 4\n",
    "max_length = 36  # Set the maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lars/Documents/test/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1094822   ['input_ids[0][0]',           \n",
      " )                           ngAndCrossAttentions(last_   40         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, None,                                            \n",
      "                             768),                                                                \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 768)                  0         ['tf_bert_model[0][0]',       \n",
      "                                                                     'tf_bert_model[0][1]']       \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 768)                  0         ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 10)                   7690      ['dropout_37[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109489930 (417.67 MB)\n",
      "Trainable params: 109489930 (417.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model_builder = BERTModelBuilderDynamic(model_name='bert-base-uncased', num_classes=num_classes)\n",
    "model = model_builder.create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 13175\n",
      "Number of validation samples: 2805\n",
      "Steps per epoch (train): 3293\n",
      "Steps per epoch (val): 701\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dynamic padding and uniform length batching\n",
    "\n",
    "# Assuming train_tensor and val_tensor are pandas dataframes\n",
    "train_tensor['Prefix_Trace'] = train_tensor['Prefix_Trace'].astype(str)\n",
    "val_tensor['Prefix_Trace'] = val_tensor['Prefix_Trace'].astype(str)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_map = {label: idx for idx, label in enumerate(train_tensor['Next_Activity'].unique())}\n",
    "train_tensor['Next_Activity'] = train_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "val_tensor['Next_Activity'] = val_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_data = Dataset.from_pandas(train_tensor)\n",
    "val_data = Dataset.from_pandas(val_tensor)\n",
    "\n",
    "# Sort the data by length\n",
    "sorted_train_data = sort_by_length(train_data, tokenizer, max_length)\n",
    "sorted_val_data = sort_by_length(val_data, tokenizer, max_length)\n",
    "\n",
    "# Initialize data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "# Create TensorFlow datasets and ensure they repeat\n",
    "tf_train_dataset = create_buckets_and_batches_bert(sorted_train_data, batch_size, data_collator).repeat()\n",
    "tf_val_dataset = create_buckets_and_batches_bert(sorted_val_data, batch_size, data_collator).repeat()\n",
    "\n",
    "# Prefetch datasets\n",
    "tf_train_dataset = tf_train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "tf_val_dataset = tf_val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch based on the length of the dataset\n",
    "train_steps_per_epoch = len(sorted_train_data) // batch_size\n",
    "val_steps_per_epoch = len(sorted_val_data) // batch_size\n",
    "\n",
    "# Debugging statements to check the sizes and steps\n",
    "print(f\"Number of training samples: {len(sorted_train_data)}\")\n",
    "print(f\"Number of validation samples: {len(sorted_val_data)}\")\n",
    "print(f\"Steps per epoch (train): {train_steps_per_epoch}\")\n",
    "print(f\"Steps per epoch (val): {val_steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callbacks\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "metrics_callback = MetricsCallbackDynamic(validation_data=tf_val_dataset, steps_per_epoch=val_steps_per_epoch)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history_helpdesk = model.fit(\n",
    "    tf_train_dataset,\n",
    "    epochs=50,  # Increase the number of epochs if necessary\n",
    "    validation_data=tf_val_dataset,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    callbacks=[metrics_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"BERT (base) training time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all datasets the models were trained\n",
    "datasets = ['helpdesk']\n",
    "\n",
    "# Ploting loss and accuracy for all datasets\n",
    "plot_loss_accuracy_comparison(history_helpdesk.history, datasets, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
