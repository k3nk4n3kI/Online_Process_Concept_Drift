{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimized Dynamic Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Source: https://keras.io/guides/keras_tuner/getting_started/#tune-model-training\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Append the directory containing the src folder to sys.path\n",
    "sys.path.append('/Users/lars/Documents/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lars/Documents/test/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "import keras_tuner\n",
    "from keras_tuner.tuners import GridSearch\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_models as tfm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, set_seed\n",
    "from tensorflow.keras.callbacks import Callback # type: ignore\n",
    "from datasets import Dataset\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from src.data.data_manager import data_loader\n",
    "from src.models.baseline_models import sort_by_length, create_buckets_and_batches_bert, BERTModelBuilderDynamic, MetricsCallbackDynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path variables for datasets\n",
    "directory = \"/Users/lars/Documents/Uni/Masterarbeit/Online_Process_Concept_Drift\"\n",
    "path_raw = \"/data/raw/\"\n",
    "path_interim = \"/data/interim/\"\n",
    "path_processed = \"/data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs available: \", len(gpus))\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(\"GPU:\", gpu)\n",
    "else:\n",
    "    print(\"No GPU available\")\n",
    "\n",
    "# Verify GPU utilization with a simple computation\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.random.normal([10000, 10000])\n",
    "    b = tf.random.normal([10000, 10000])\n",
    "    start_time = time.time()\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"GPU computation time: \", time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducability\n",
    "\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = data_loader(directory, path_interim, \"Long_Helpdesk_train\")\n",
    "val_tensor = data_loader(directory, path_interim, \"Long_Helpdesk_val\")\n",
    "test_tensor = data_loader(directory, path_interim, \"Long_Helpdesk_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prefix_Trace</th>\n",
       "      <th>Next_Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assign-seriousness</td>\n",
       "      <td>take-in-charge-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket</td>\n",
       "      <td>take-in-charge-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket take-...</td>\n",
       "      <td>resolve-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket take-...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket take-...</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13170</th>\n",
       "      <td>assign-seriousness</td>\n",
       "      <td>take-in-charge-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13172</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket wait</td>\n",
       "      <td>resolve-ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13173</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket wait ...</td>\n",
       "      <td>closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13174</th>\n",
       "      <td>assign-seriousness take-in-charge-ticket wait ...</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13175 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Prefix_Trace  \\\n",
       "0                                     assign-seriousness   \n",
       "1               assign-seriousness take-in-charge-ticket   \n",
       "2      assign-seriousness take-in-charge-ticket take-...   \n",
       "3      assign-seriousness take-in-charge-ticket take-...   \n",
       "4      assign-seriousness take-in-charge-ticket take-...   \n",
       "...                                                  ...   \n",
       "13170                                 assign-seriousness   \n",
       "13171           assign-seriousness take-in-charge-ticket   \n",
       "13172      assign-seriousness take-in-charge-ticket wait   \n",
       "13173  assign-seriousness take-in-charge-ticket wait ...   \n",
       "13174  assign-seriousness take-in-charge-ticket wait ...   \n",
       "\n",
       "               Next_Activity  \n",
       "0      take-in-charge-ticket  \n",
       "1      take-in-charge-ticket  \n",
       "2             resolve-ticket  \n",
       "3                     closed  \n",
       "4                        end  \n",
       "...                      ...  \n",
       "13170  take-in-charge-ticket  \n",
       "13171                   wait  \n",
       "13172         resolve-ticket  \n",
       "13173                 closed  \n",
       "13174                    end  \n",
       "\n",
       "[13175 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Checking for Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable for GPU memory management\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Enable mixed precision for better performance and reduced memory usage\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear any existing GPU memory state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reduce TensorFlow logging verbosity\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_classes = 10\n",
    "batch_size = 4\n",
    "max_length = 36  # Set the maximum sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lars/Documents/test/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-07-02 10:27:45.707942: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-07-02 10:27:45.707964: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-07-02 10:27:45.707967: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-07-02 10:27:45.708000: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-02 10:27:45.708013: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, None)]               0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel  TFBaseModelOutputWithPooli   1094822   ['input_ids[0][0]',           \n",
      " )                           ngAndCrossAttentions(last_   40         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, None,                                            \n",
      "                             768),                                                                \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 768)                  0         ['tf_bert_model[0][0]',       \n",
      "                                                                     'tf_bert_model[0][1]']       \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 768)                  0         ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 10)                   7690      ['dropout_37[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109489930 (417.67 MB)\n",
      "Trainable params: 109489930 (417.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "model_builder = BERTModelBuilderDynamic(model_name='bert-base-uncased', num_classes=num_classes)\n",
    "model = model_builder.create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lars/Documents/test/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 13175\n",
      "Number of validation samples: 2805\n",
      "Steps per epoch (train): 3293\n",
      "Steps per epoch (val): 701\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dynamic padding and uniform length batching\n",
    "\n",
    "# Assuming train_tensor and val_tensor are pandas dataframes\n",
    "train_tensor['Prefix_Trace'] = train_tensor['Prefix_Trace'].astype(str)\n",
    "val_tensor['Prefix_Trace'] = val_tensor['Prefix_Trace'].astype(str)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_map = {label: idx for idx, label in enumerate(train_tensor['Next_Activity'].unique())}\n",
    "train_tensor['Next_Activity'] = train_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "val_tensor['Next_Activity'] = val_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_data = Dataset.from_pandas(train_tensor)\n",
    "val_data = Dataset.from_pandas(val_tensor)\n",
    "\n",
    "# Sort the data by length\n",
    "sorted_train_data = sort_by_length(train_data, tokenizer, max_length)\n",
    "sorted_val_data = sort_by_length(val_data, tokenizer, max_length)\n",
    "\n",
    "# Initialize data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "# Create TensorFlow datasets and ensure they repeat\n",
    "tf_train_dataset = create_buckets_and_batches_bert(sorted_train_data, batch_size, data_collator).repeat()\n",
    "tf_val_dataset = create_buckets_and_batches_bert(sorted_val_data, batch_size, data_collator).repeat()\n",
    "\n",
    "# Prefetch datasets\n",
    "tf_train_dataset = tf_train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "tf_val_dataset = tf_val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch based on the length of the dataset\n",
    "train_steps_per_epoch = len(sorted_train_data) // batch_size\n",
    "val_steps_per_epoch = len(sorted_val_data) // batch_size\n",
    "\n",
    "# Debugging statements to check the sizes and steps\n",
    "print(f\"Number of training samples: {len(sorted_train_data)}\")\n",
    "print(f\"Number of validation samples: {len(sorted_val_data)}\")\n",
    "print(f\"Steps per epoch (train): {train_steps_per_epoch}\")\n",
    "print(f\"Steps per epoch (val): {val_steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callbacks\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "metrics_callback = MetricsCallbackDynamic(validation_data=tf_val_dataset, steps_per_epoch=val_steps_per_epoch)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history_helpdesk = model.fit(\n",
    "    tf_train_dataset,\n",
    "    epochs=50,  # Increase the number of epochs if necessary\n",
    "    validation_data=tf_val_dataset,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    callbacks=[metrics_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"BERT (base) training time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_save_dir = '/home/lars.gsaenger/test/models/models_pretrained/histories'\n",
    "\n",
    "# Define the model and history file paths\n",
    "history_save_path = os.path.join(history_save_dir, 'tuned_dynamic_bert_bpic2018_history.pkl')\n",
    "\n",
    "# Save the history object returned by model.fit()\n",
    "with open(history_save_path, 'wb') as f:\n",
    "    pickle.dump(history_helpdesk.history, f)\n",
    "\n",
    "print(f\"History saved to {history_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_history(history):\n",
    "    # Extracting data from history\n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_accuracy = history['accuracy']\n",
    "    val_accuracy = history['val_accuracy']\n",
    "\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    # Plotting training and validation loss and accuracy in subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Plotting training and validation loss\n",
    "    axs[0].plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "    axs[0].plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "    axs[0].set_title('Training and Validation Loss')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plotting training and validation accuracy\n",
    "    axs[1].plot(epochs, train_accuracy, 'b', label='Training Accuracy')\n",
    "    axs[1].plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "    axs[1].set_title('Training and Validation Accuracy')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Assuming 'model_history' is the history object obtained after training the model\n",
    "plot_model_history(history_helpdesk.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "epochs = 5\n",
    "learning_rate = 1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(len(train_tensor['Prefix_Trace'])/batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(0.1*num_train_steps)\n",
    "#learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, decay_steps=num_train_steps, decay_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "warumup_schedule = tfm.optimization.lr_schedule.LinearWarmup(warmup_learning_rate=0, after_warmup_lr_sched=linear_decay, warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(0, num_train_steps)]\n",
    "y = [warumup_schedule(xi).numpy() for xi in x]\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('Train step')\n",
    "plt.ylabel('Learning rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "steps = np.arange(0, num_train_steps, 1)\n",
    "lrs=[]\n",
    "\n",
    "for step in steps:\n",
    "    lrs.append(warumup_schedule(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1496338e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2992677e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4489014e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5985353e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.748169e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.8978028e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0474365e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.197071e-09>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0346705e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1496338e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2645972e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.37956055e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.494524e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6094873e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7244508e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8394141e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9543775e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.069341e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1843041e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2992676e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.414231e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5291945e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6441576e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7591211e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8740844e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.989048e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.1040113e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2189746e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.333938e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4489016e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5638646e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6788283e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7937912e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.908755e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0237182e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.138682e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.253645e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.3686082e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.483572e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5985352e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.7134982e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.828462e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.9434252e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.058389e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.1733522e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.2883152e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.403279e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.5182422e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.6332052e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.748169e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8631322e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.978096e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.093059e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.2080225e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.322986e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.437949e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.552912e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.667876e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.7828395e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.897803e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.012766e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.127729e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.242693e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.3576565e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.4726195e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.5875825e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.702547e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.81751e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.932473e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0474365e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.1623995e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.277364e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.392327e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.50729e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.6222535e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.7372165e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8521794e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.967144e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.082107e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.1970705e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.3120335e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.4269964e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.541961e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.656924e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.7718875e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.8868504e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.00018134e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0116778e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0231741e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.03467045e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.04616674e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.05766304e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0691594e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0806558e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0921521e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.10364844e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.11514474e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.12664104e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1381375e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1496338e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.16113014e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.17262644e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.18412274e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1956192e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2071155e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2186118e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.230108e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2416045e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2531008e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2645972e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2760935e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2875898e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.2990861e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3105824e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3220789e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3335752e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3450715e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3565679e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3680642e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.3795606e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.391057e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4025532e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4140495e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4255458e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4370421e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4485386e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4600349e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4715313e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4830276e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.4945239e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5060203e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5175165e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.529013e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5405094e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5520055e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.563502e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5749983e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5864946e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.597991e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6094873e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6209837e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6324799e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6439763e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6554728e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6669689e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6784654e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.6899617e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.701458e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7129543e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7244507e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7359471e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7474433e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7589397e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7704359e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7819323e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.7934288e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.804925e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8164214e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8279177e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8394141e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8509104e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8624067e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8739031e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8853993e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.8968957e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9083922e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9198883e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9313848e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.942881e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9543775e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9658738e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9773701e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.9888665e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0003627e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0118591e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0233556e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0348517e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0463482e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0578445e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0693409e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0808372e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0923335e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1038299e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1153261e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1268225e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1383188e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1498151e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1613116e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1728079e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1843042e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.1958004e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2072969e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2187933e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2302895e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2417859e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2532821e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2647785e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.276275e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2877713e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2992675e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3107638e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3222603e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3337567e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3452529e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3567493e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3682455e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3797419e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.3912384e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.4027347e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.414231e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.4257272e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.4372235e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.44872e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.460216e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.4717127e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.483209e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.4947053e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5062016e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.517698e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5291945e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5406905e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.552187e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5636834e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5751797e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.586676e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5981723e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6096689e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.621165e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6326614e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6441577e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.655654e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6671503e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6786466e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.690143e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7016395e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7131358e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.724632e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7361284e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7476247e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7591213e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.7706173e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.782114e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.79361e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8051065e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8166028e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.828099e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8395954e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8510917e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8625882e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8740843e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.8855808e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.897077e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9085734e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9200697e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.931566e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9430626e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.954559e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9660552e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9775512e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.9890478e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.000544e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0120407e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.023537e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.035033e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0465296e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.058026e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0695222e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0810187e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.0925148e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.104011e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.1155076e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.127004e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.1385005e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.1499965e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.1614928e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.172989e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.1844857e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.195982e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.207478e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2189746e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.230471e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2419675e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2534638e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2649598e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2764564e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2879527e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.299449e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3109455e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3224416e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3339379e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3454344e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3569307e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.368427e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3799233e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.3914196e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.402916e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4144125e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4259085e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4374048e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4489014e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4603977e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4718943e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4833903e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.4948866e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.506383e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5178795e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5293758e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5408718e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5523684e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5638647e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5753612e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5868575e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.5983535e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.60985e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6213464e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6328427e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6443393e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6558353e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6673316e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6788282e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.6903245e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7018208e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.713317e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7248134e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7363097e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7478063e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7593026e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7707986e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7822952e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.7937914e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.805288e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.8167843e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.8282803e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.8397766e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.8512732e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.8627695e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.874266e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.885762e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.8972584e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.908755e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.9202513e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.9317476e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.943244e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.9547402e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.9662365e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.977733e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.9892294e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0007254e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.012222e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0237182e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0352145e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.046711e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.058207e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0697034e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0812e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.0926963e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.104193e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.115689e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.1271852e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.1386818e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.150178e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.1616744e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.1731704e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.184667e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.1961633e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.2076599e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.219156e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.2306522e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.2421487e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.253645e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.2651413e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.2766376e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.288134e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.2996302e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.3111268e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.322623e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.334119e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.3456157e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.357112e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.3686083e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.380105e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.391601e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.4030972e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.4145938e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.42609e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.4375867e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.4490827e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.460579e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.4720755e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.4835718e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.495068e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5065642e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5180607e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.529557e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5410536e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.55255e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.564046e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5755425e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.5870388e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.598535e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.6100317e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.6215277e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.633024e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.6445206e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.656017e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.6675135e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.6790095e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.6905058e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.702002e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.7134986e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.724995e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.736491e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.7479875e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.7594838e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.77098e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.7824767e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.793973e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8054693e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8169653e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.828462e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8399585e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8514545e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.862951e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.874447e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8859437e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.89744e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.908936e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.920432e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.931929e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.9434254e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.9549215e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.966418e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.977914e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.9894106e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.000907e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.012403e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0239e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.035396e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0468924e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.058389e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.069885e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.081381e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0928776e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.104374e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.11587e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.127367e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.138863e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.1503594e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.161856e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.173352e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.184848e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.1963445e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.207841e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.2193377e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.230834e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.24233e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.2538263e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.265323e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.276819e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.2883155e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.2998115e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.311308e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.3228047e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.3343007e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.345797e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.357293e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.36879e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.380286e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.3917825e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.403279e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.414775e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.4262716e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.4377676e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.449264e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.460761e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.472257e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.483753e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.4952494e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.506746e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.5182426e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.5297386e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.5412346e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.552731e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.564228e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.575724e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.58722e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.5987164e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.610213e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.6217095e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.6332055e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.6447016e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.656198e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.667695e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.679191e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.6906873e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7021833e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.71368e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7251765e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7366725e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7481685e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.759665e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7711617e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7826577e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.794154e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8056503e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.817147e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8286435e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8401395e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.851636e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.863132e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8746286e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.886125e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.897621e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.909118e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.920614e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.9321104e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.9436064e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.9551024e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.9665996e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.9780956e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.989592e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.001088e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.012584e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0240814e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0355774e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.047074e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.05857e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.070066e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.081563e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.093059e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.104556e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.116052e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.127548e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1390443e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1505403e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1620375e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1735335e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1850295e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.196526e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.208022e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.219519e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.231015e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.2425113e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.254008e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.265504e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.277001e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.288497e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.299993e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3114896e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3229857e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.334482e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.345978e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.357475e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3689714e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3804674e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.391964e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.40346e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.414956e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.426453e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.437949e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.449446e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.460942e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.472438e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.483935e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.495431e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.5069275e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.5184236e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.5299196e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.541416e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.552913e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.5644093e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.5759053e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.5874013e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.598898e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.610394e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.621891e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.633387e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.644883e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.6563797e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.6678757e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.679373e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.690869e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.702365e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.7138615e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.7253575e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.736854e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.7483506e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.7598467e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.771343e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.782839e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.794336e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.805832e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.817328e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.828825e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.840321e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.851817e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.8633136e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.8748096e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.886307e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.897803e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.909299e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.9207954e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.9322914e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.9437885e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.9552846e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.9667806e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.978277e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.989773e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.00127e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.012766e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.0242623e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.035759e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.047255e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.0587515e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.0702475e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.0817435e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.0932407e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.1047367e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.1162333e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.1277293e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.1392253e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.1507225e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.1622185e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.173715e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.185211e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.196707e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.2082037e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.2197e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.231197e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.242693e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.254189e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.2656854e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.2771815e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.2886786e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.3001746e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.3116706e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.323167e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.334663e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.3461604e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.3576564e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.3691524e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.380649e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.392145e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.4036416e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.415138e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.426634e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.438131e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.449627e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.4611233e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.4726194e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.4841154e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.4956125e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.5071085e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.518605e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.530101e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.541597e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.5530943e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.5645903e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.576087e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.587583e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.599079e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.610576e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.622072e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.6335687e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.6450647e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.6565607e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.668057e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.679553e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.6910504e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.7025464e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.7140425e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.725539e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.737035e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.748532e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.760028e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.771524e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.783021e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.794517e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.806014e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.81751e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.829006e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.8405026e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.8519986e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.863495e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.874991e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.886488e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.8979843e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.9094804e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.920977e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.932473e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.943969e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.955466e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.966962e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.9784587e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.989955e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.001451e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.012948e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.024444e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0359405e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0474365e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0589325e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.070429e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.0819257e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.093422e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.104918e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.116414e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.127911e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.139407e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.150904e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.1624e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.173896e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.1853926e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.1968886e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.208386e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.219882e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.231378e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.2428744e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.2543704e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.265867e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.2773636e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.2888596e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.300356e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.311852e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.323349e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.334845e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.346341e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.357838e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.369334e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.38083e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.3923265e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4038226e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4153197e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.426816e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.438312e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4498083e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4613043e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4728015e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4842975e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.4957935e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.50729e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.518786e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.5302827e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.5417787e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.553275e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.564772e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.576268e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.5877645e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.5992605e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.6107565e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.6222536e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.6337496e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.645246e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.656742e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.668238e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.6797354e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.6912314e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.702728e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.714224e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.72572e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.7372166e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.748713e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.76021e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.771706e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.783202e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.7946984e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8061944e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8176915e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8291875e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8406836e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.85218e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.863676e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8751733e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8866693e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.8981653e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.909662e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.921158e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.9326545e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.944151e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.955647e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.9671437e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.9786397e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=8.990136e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.0016323e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.0131283e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.0246255e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.0361215e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.047618e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.059114e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.07061e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.082107e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.093603e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.1051e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.116596e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.128092e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.139589e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.151085e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.1625816e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.1740776e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.1855736e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.19707e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.208566e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.2200634e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.2315594e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.2430554e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.254552e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.266048e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.277545e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.289041e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.300537e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.312034e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.32353e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.335027e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.346523e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.358019e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.3695155e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.3810115e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.392508e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.404004e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.4155007e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.426997e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.4384933e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.44999e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.461486e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.472982e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.484479e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.495975e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.5074716e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.5189677e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.5304637e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.54196e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.553456e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.564953e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.576449e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.587945e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.599443e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.610939e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.622435e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.633931e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.645427e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.656924e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.66842e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.679917e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.691413e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.702909e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.714406e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.725902e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.737398e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.748894e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.76039e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.771887e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.783383e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.79488e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.806377e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.817873e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.829369e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.840865e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.852362e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.863858e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.875354e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.886851e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.898347e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.909843e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.92134e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.932836e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.944332e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.955828e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.967324e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.978821e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=9.990317e-07>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0001814e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.001331e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0024806e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0036302e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.00478e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0059296e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0070792e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0082288e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0093785e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0105281e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0116778e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0128274e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.013977e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0151266e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0162762e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0174259e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0185755e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0197251e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0208748e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0220244e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.023174e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0243238e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0254734e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.026623e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0277726e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0289223e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0300719e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0312215e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0323712e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0335208e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0346704e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.03582e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0369696e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0381193e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0392689e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0404186e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0415682e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0427178e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0438675e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0450171e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0461667e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0473163e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.048466e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0496157e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0507653e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.051915e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0530646e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0542142e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0553638e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0565134e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0576631e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0588127e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0599623e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.061112e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0622616e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0634113e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0645609e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0657105e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0668601e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0680097e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0691595e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.070309e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0714587e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0726084e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.073758e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0749076e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0760572e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0772068e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0783565e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0795061e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0806558e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0818054e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.082955e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0841047e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0852543e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0864039e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0875535e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0887031e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0898528e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0910024e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0921522e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0933018e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0944514e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.095601e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0967506e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0979003e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0990499e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1001995e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1013492e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1024988e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1036485e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1047981e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1059477e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1070973e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1082469e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1093966e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1105462e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1116958e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1128456e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1139952e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1151448e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1162944e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.117444e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1185937e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1197433e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.120893e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1220426e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1231922e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1243419e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1254915e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1266411e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1277907e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1289403e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.13009e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1312396e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1323893e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.133539e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1346885e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1358381e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1369877e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1381375e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1392871e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1404367e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1415864e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.142736e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1438856e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1450353e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1461849e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1473345e-06>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.1484841e-06>,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    }
   ],
   "source": [
    "optimzer = tf.keras.optimizers.experimental.AdamW(learning_rate=warumup_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tune Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable for GPU memory management\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Enable mixed precision for better performance and reduced memory usage\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear any existing GPU memory state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reduce TensorFlow logging verbosity\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "max_length = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaped BERT model to tune learning rate\n",
    "\n",
    "class BERTModelBuilderDynamic():\n",
    "    def __init__(self, model_name, num_classes, batch_size, epochs):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def create_model(self, hp):\n",
    "\n",
    "        # Load the pretrained BERT model\n",
    "        encoder = TFAutoModel.from_pretrained(self.model_name)\n",
    "\n",
    "        # Input layer for input_ids and attention_masks\n",
    "        input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "        attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get the pooled output and make sure it is of type tf.float32\n",
    "        pooled_output = tf.keras.layers.Lambda(lambda x: tf.cast(x.pooler_output, tf.float32))(encoder_outputs)\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n",
    "\n",
    "        # Final dense layer for classification with softmax activation function and L2 regularization\n",
    "        output = tf.keras.layers.Dense(self.num_classes, activation='softmax', dtype=tf.float32)(dropout)\n",
    "        \n",
    "        # Create model\n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "        learning_rate = hp.Choice('learning_rate', values=[5e-5, 3e-5, 2e-5])\n",
    "\n",
    "        steps_per_epoch = int(len(train_tensor['Prefix_Trace'])/self.batch_size)\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "        linear_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, decay_steps=num_train_steps, decay_rate=0.01)\n",
    "        optimizer = tfm.optimization.lr_schedule.LinearWarmup(warmup_learning_rate=0, after_warmup_lr_sched=linear_decay, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Compile model with AdamW as optimzer\n",
    "        model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=optimizer),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dynamic padding and uniform length batching\n",
    "\n",
    "# Assuming train_tensor and val_tensor are pandas dataframes\n",
    "train_tensor['Prefix_Trace'] = train_tensor['Prefix_Trace'].astype(str)\n",
    "val_tensor['Prefix_Trace'] = val_tensor['Prefix_Trace'].astype(str)\n",
    "test_tensor['Prefix_Trace'] = test_tensor['Prefix_Trace'].astype(str)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_map_train = {label: idx for idx, label in enumerate(train_tensor['Next_Activity'].unique())}\n",
    "label_map_val = {label: idx for idx, label in enumerate(val_tensor['Next_Activity'].unique())}\n",
    "label_map_test = {label: idx for idx, label in enumerate(test_tensor['Next_Activity'].unique())}\n",
    "print(f\"Train: {label_map_train}\")\n",
    "print(f\"Val: {label_map_val}\")\n",
    "print(f\"Test: {label_map_test}\")\n",
    "train_tensor['Next_Activity'] = train_tensor['Next_Activity'].map(label_map_train).astype(int)\n",
    "val_tensor['Next_Activity'] = val_tensor['Next_Activity'].map(label_map_train).astype(int)\n",
    "test_tensor['Next_Activity'] = test_tensor['Next_Activity'].map(label_map_train).astype(int)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_data = Dataset.from_pandas(train_tensor)\n",
    "val_data = Dataset.from_pandas(val_tensor)\n",
    "test_data = Dataset.from_pandas(test_tensor)\n",
    "\n",
    "# Sort the data by length\n",
    "sorted_train_data = sort_by_length(train_data, tokenizer, max_length)\n",
    "sorted_val_data = sort_by_length(val_data, tokenizer, max_length)\n",
    "sorted_test_data = sort_by_length(test_data, tokenizer, max_length)\n",
    "\n",
    "# Initialize data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "# Create TensorFlow datasets and ensure they repeat\n",
    "tf_train_dataset = create_buckets_and_batches_bert(sorted_train_data, batch_size, data_collator)\n",
    "tf_val_dataset = create_buckets_and_batches_bert(sorted_val_data, batch_size, data_collator)\n",
    "tf_test_dataset = create_buckets_and_batches_bert(sorted_test_data, batch_size, data_collator)\n",
    "\n",
    "# Prefetch datasets\n",
    "tf_train_dataset = tf_train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "tf_val_dataset = tf_val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "tf_test_dataset = tf_test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch based on the length of the dataset\n",
    "train_steps_per_epoch = len(sorted_train_data) // batch_size\n",
    "val_steps_per_epoch = len(sorted_val_data) // batch_size\n",
    "test_steps_per_epoch = len(sorted_test_data) // batch_size\n",
    "\n",
    "\n",
    "# Debugging statements to check the sizes and steps\n",
    "print(f\"Number of training samples: {len(sorted_train_data)}\")\n",
    "print(f\"Number of validation samples: {len(sorted_val_data)}\")\n",
    "print(f\"Number of test samples: {len(sorted_test_data)}\")\n",
    "print(f\"Steps per epoch (train): {train_steps_per_epoch}\")\n",
    "print(f\"Steps per epoch (val): {val_steps_per_epoch}\")\n",
    "print(f\"Steps per epoch (test): {test_steps_per_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Class\n",
    "model_builder = BERTModelBuilderDynamic(model_name='bert-base-uncased', num_classes=num_classes, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = GridSearch(\n",
    "    model_builder.create_model,\n",
    "    objective = 'val_loss',\n",
    "    max_trials = 15,\n",
    "    executions_per_trial = 1,\n",
    "    directory=\"Hyperparameter\",\n",
    "    project_name=\"learning_rate_Helpdesk_v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(tf_train_dataset, epochs = epochs, validation_data = tf_val_dataset, callbacks=[early_stopping], steps_per_epoch=train_steps_per_epoch, validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "lr = best_lr.get('learning_rate')\n",
    "\n",
    "# Save best learning rate as txt file\n",
    "with open('/home/lars.gsaenger/test/notebooks/best_learning_rate.txt', 'w') as f:\n",
    "    f.write(f\"Best Learning Rate: {lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tune Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "epochs = 5\n",
    "num_classes = 10\n",
    "max_length = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable for GPU memory management\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Enable mixed precision for better performance and reduced memory usage\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear any existing GPU memory state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reduce TensorFlow logging verbosity\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Base model adjusted with fine-tuned learning rate\n",
    "\n",
    "class BERTModelBuilderDynamic():\n",
    "    def __init__(self, model_name, num_classes, batch_size, epochs):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def create_model(self):\n",
    "\n",
    "        # Load the pretrained BERT model\n",
    "        encoder = TFAutoModel.from_pretrained(self.model_name)\n",
    "\n",
    "        # Input layer for input_ids and attention_masks\n",
    "        input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "        attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get the pooled output and make sure it is of type tf.float32\n",
    "        pooled_output = tf.keras.layers.Lambda(lambda x: tf.cast(x.pooler_output, tf.float32))(encoder_outputs)\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n",
    "\n",
    "        # Final dense layer for classification with softmax activation function and L2 regularization\n",
    "        output = tf.keras.layers.Dense(self.num_classes, activation='softmax', dtype=tf.float32)(dropout)\n",
    "        \n",
    "        # Create model\n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "        steps_per_epoch = int(len(train_tensor['Prefix_Trace'])/self.batch_size)\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "        linear_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-05, decay_steps=num_train_steps, decay_rate=0.01)\n",
    "        optimizer = tfm.optimization.lr_schedule.LinearWarmup(warmup_learning_rate=0, after_warmup_lr_sched=linear_decay, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Compile model with AdamW as optimzer\n",
    "        model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=optimizer),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_dict = {}\n",
    "evaluation_dict = {}\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    print(f\"Current Batch Size: {batch_size}\")\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Dynamic padding and uniform length batching\n",
    "\n",
    "    # Assuming train_tensor and val_tensor are pandas dataframes\n",
    "    train_tensor['Prefix_Trace'] = train_tensor['Prefix_Trace'].astype(str)\n",
    "    val_tensor['Prefix_Trace'] = val_tensor['Prefix_Trace'].astype(str)\n",
    "    test_tensor['Prefix_Trace'] = test_tensor['Prefix_Trace'].astype(str)\n",
    "\n",
    "    # Convert labels to integers\n",
    "    label_map = {label: idx for idx, label in enumerate(train_tensor['Next_Activity'].unique())}\n",
    "    train_tensor['Next_Activity'] = train_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "    val_tensor['Next_Activity'] = val_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "    test_tensor['Next_Activity'] = test_tensor['Next_Activity'].map(label_map).astype(int)\n",
    "\n",
    "    # Convert to Hugging Face datasets\n",
    "    train_data = Dataset.from_pandas(train_tensor)\n",
    "    val_data = Dataset.from_pandas(val_tensor)\n",
    "    test_data = Dataset.from_pandas(test_tensor)\n",
    "\n",
    "    # Sort the data by length\n",
    "    sorted_train_data = sort_by_length(train_data, tokenizer, max_length)\n",
    "    sorted_val_data = sort_by_length(val_data, tokenizer, max_length)\n",
    "    sorted_test_data = sort_by_length(test_data, tokenizer, max_length)\n",
    "\n",
    "    # Initialize data collator\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "    # Create TensorFlow datasets and ensure they repeat\n",
    "    tf_train_dataset = create_buckets_and_batches_bert(sorted_train_data, batch_size, data_collator)\n",
    "    tf_val_dataset = create_buckets_and_batches_bert(sorted_val_data, batch_size, data_collator)\n",
    "    tf_test_dataset = create_buckets_and_batches_bert(sorted_test_data, batch_size, data_collator)\n",
    "\n",
    "    # Prefetch datasets\n",
    "    tf_train_dataset = tf_train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    tf_val_dataset = tf_val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    tf_test_dataset = tf_test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Calculate steps per epoch based on the length of the dataset\n",
    "    train_steps_per_epoch = len(sorted_train_data) // batch_size\n",
    "    val_steps_per_epoch = len(sorted_val_data) // batch_size\n",
    "    test_steps_per_epoch = len(sorted_test_data) // batch_size\n",
    "\n",
    "\n",
    "    # Debugging statements to check the sizes and steps\n",
    "    print(f\"Number of training samples: {len(sorted_train_data)}\")\n",
    "    print(f\"Number of validation samples: {len(sorted_val_data)}\")\n",
    "    print(f\"Number of test samples: {len(sorted_test_data)}\")\n",
    "    print(f\"Steps per epoch (train): {train_steps_per_epoch}\")\n",
    "    print(f\"Steps per epoch (val): {val_steps_per_epoch}\")\n",
    "    print(f\"Steps per epoch (test): {test_steps_per_epoch}\")\n",
    "\n",
    "    # Build and compile the model\n",
    "    model_builder = BERTModelBuilderDynamic(model_name='bert-base-uncased', num_classes=num_classes, batch_size=batch_size, epochs=epochs)\n",
    "    model = model_builder.create_model()\n",
    "    model.summary()\n",
    "\n",
    "    # Set callbacks\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    metrics_callback = MetricsCallbackDynamic(validation_data=tf_val_dataset, steps_per_epoch=val_steps_per_epoch)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Train the model\n",
    "    history_helpdesk = model.fit(\n",
    "        tf_train_dataset,\n",
    "        epochs=epochs,  # Increase the number of epochs if necessary\n",
    "        validation_data=tf_val_dataset,\n",
    "        steps_per_epoch=train_steps_per_epoch,\n",
    "        validation_steps=val_steps_per_epoch,\n",
    "        callbacks=[metrics_callback, early_stopping_callback]\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"BERT (base) training time: {end_time - start_time} seconds\")\n",
    "\n",
    "    evaluation = model.evaluate(tf_test_dataset, steps=test_steps_per_epoch)\n",
    "\n",
    "    batch_size_dict[batch_size] = history_helpdesk.history\n",
    "    evaluation_dict[batch_size] = evaluation\n",
    "\n",
    "    print(f\"Loss for batch size {batch_size}: {evaluation[0]}\")\n",
    "    print(f\"Accuracy for batch size {batch_size}: {evaluation[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fit final model and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable for GPU memory management\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Enable mixed precision for better performance and reduced memory usage\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Clear any existing GPU memory state\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Reduce TensorFlow logging verbosity\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_classes = 42\n",
    "batch_size = 16\n",
    "max_length = 242\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Dynamic padding and uniform length batching\n",
    "\n",
    "# Assuming train_tensor and val_tensor are pandas dataframes\n",
    "train_tensor['Prefix_Trace'] = train_tensor['Prefix_Trace'].astype(str)\n",
    "val_tensor['Prefix_Trace'] = val_tensor['Prefix_Trace'].astype(str)\n",
    "test_tensor['Prefix_Trace'] = test_tensor['Prefix_Trace'].astype(str)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_map_train = {label: idx for idx, label in enumerate(train_tensor['Next_Activity'].unique())}\n",
    "label_map_val = {label: idx for idx, label in enumerate(val_tensor['Next_Activity'].unique())}\n",
    "label_map_test = {label: idx for idx, label in enumerate(test_tensor['Next_Activity'].unique())}\n",
    "train_tensor['Next_Activity'] = train_tensor['Next_Activity'].map(label_map_train).astype(int)\n",
    "val_tensor['Next_Activity'] = val_tensor['Next_Activity'].map(label_map_train).astype(int)\n",
    "test_tensor['Next_Activity'] = test_tensor['Next_Activity'].map(label_map_train).astype(int)\n",
    "\n",
    "# Convert to Hugging Face datasets\n",
    "train_data = Dataset.from_pandas(train_tensor)\n",
    "val_data = Dataset.from_pandas(val_tensor)\n",
    "test_data = Dataset.from_pandas(test_tensor)\n",
    "\n",
    "# Sort the data by length\n",
    "sorted_train_data = sort_by_length(train_data, tokenizer, max_length)\n",
    "sorted_val_data = sort_by_length(val_data, tokenizer, max_length)\n",
    "sorted_test_data = sort_by_length(test_data, tokenizer, max_length)\n",
    "\n",
    "# Initialize data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "# Create TensorFlow datasets and ensure they repeat\n",
    "tf_train_dataset = create_buckets_and_batches_bert(sorted_train_data, batch_size, data_collator)\n",
    "tf_val_dataset = create_buckets_and_batches_bert(sorted_val_data, batch_size, data_collator)\n",
    "tf_test_dataset = create_buckets_and_batches_bert(sorted_test_data, batch_size, data_collator)\n",
    "\n",
    "# Prefetch datasets\n",
    "tf_train_dataset = tf_train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "tf_val_dataset = tf_val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "tf_test_dataset = tf_test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Calculate steps per epoch based on the length of the dataset\n",
    "train_steps_per_epoch = len(sorted_train_data) // batch_size\n",
    "val_steps_per_epoch = len(sorted_val_data) // batch_size\n",
    "test_steps_per_epoch = len(sorted_test_data) // batch_size\n",
    "\n",
    "\n",
    "# Debugging statements to check the sizes and steps\n",
    "print(f\"Number of training samples: {len(sorted_train_data)}\")\n",
    "print(f\"Number of validation samples: {len(sorted_val_data)}\")\n",
    "print(f\"Number of test samples: {len(sorted_test_data)}\")\n",
    "print(f\"Steps per epoch (train): {train_steps_per_epoch}\")\n",
    "print(f\"Steps per epoch (val): {val_steps_per_epoch}\")\n",
    "print(f\"Steps per epoch (test): {test_steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallbackDynamic(Callback):\n",
    "    '''\n",
    "    Custom callback for calculating, printing, and storing F1 Score, Precision, and Recall at the end of each epoch during training.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, validation_data, steps_per_epoch):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        # Initialize lists to store the metrics\n",
    "        self.f1_scores = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_pred = []\n",
    "        val_true = []\n",
    "\n",
    "        # Process each batch in validation dataset\n",
    "        for step, (x_val, y_val) in enumerate(self.validation_data.take(self.steps_per_epoch)):\n",
    "            y_pred = self.model.predict(x_val, verbose=0)\n",
    "            y_pred = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "            # Accumulate predictions and true labels\n",
    "            val_pred.extend(y_pred.numpy())\n",
    "            val_true.extend(y_val.numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        f1 = f1_score(val_true, val_pred, average='weighted')\n",
    "        precision = precision_score(val_true, val_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(val_true, val_pred, average='weighted', zero_division=0)\n",
    "\n",
    "        # Store metrics\n",
    "        self.f1_scores.append(f1)\n",
    "        self.precisions.append(precision)\n",
    "        self.recalls.append(recall)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f' â€” val_f1: {f1:.4f} â€” val_precision: {precision:.4f} â€” val_recall: {recall:.4f}')\n",
    "\n",
    "        # Optionally, add these metrics to the logs dictionary\n",
    "        logs['val_f1'] = f1\n",
    "        logs['val_precision'] = precision\n",
    "        logs['val_recall'] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTModelBuilderDynamic():\n",
    "    def __init__(self, model_name, num_classes, batch_size, epochs):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def create_model(self):\n",
    "\n",
    "        # Load the pretrained BERT model\n",
    "        encoder = TFAutoModel.from_pretrained(self.model_name)\n",
    "\n",
    "        # Input layer for input_ids and attention_masks\n",
    "        input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "        attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get the pooled output and make sure it is of type tf.float32\n",
    "        pooled_output = tf.keras.layers.Lambda(lambda x: tf.cast(x.pooler_output, tf.float32))(encoder_outputs)\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n",
    "\n",
    "        # Final dense layer for classification with softmax activation function\n",
    "        output = tf.keras.layers.Dense(self.num_classes, activation='softmax', dtype=tf.float32)(dropout)\n",
    "        \n",
    "        # Create model\n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "        steps_per_epoch = int(len(train_tensor['Prefix_Trace'])/self.batch_size)\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "        linear_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-5, decay_steps=num_train_steps, decay_rate=0.01)\n",
    "        optimizer = tfm.optimization.lr_schedule.LinearWarmup(warmup_learning_rate=0, after_warmup_lr_sched=linear_decay, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Compile model with AdamW as optimzer\n",
    "        model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=optimizer),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model_builder = BERTModelBuilderDynamic(model_name='bert-base-uncased', num_classes=num_classes, batch_size=batch_size, epochs=epochs)\n",
    "model = model_builder.create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callbacks\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "metrics_callback = MetricsCallbackDynamic(validation_data=tf_val_dataset, steps_per_epoch=val_steps_per_epoch)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history_helpdesk = model.fit(\n",
    "    tf_train_dataset,\n",
    "    epochs=5,  # Increase the number of epochs if necessary\n",
    "    validation_data=tf_val_dataset,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    callbacks=[metrics_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"BERT (base) training time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "\n",
    "model_save_path = '/home/lars.gsaenger/test/models/Weights_BPIC2018_Tuned/Weights_BPIC2018_Tuned'\n",
    "model.save_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories to save the model and history\n",
    "history_save_dir = '/home/lars.gsaenger/test/models/models_pretrained/histories'\n",
    "\n",
    "# Define the model and history file paths\n",
    "history_save_path = os.path.join(history_save_dir, 'tuned_dynamic_bert_bpic2018_history.pkl')\n",
    "\n",
    "# Save the history object returned by model.fit()\n",
    "with open(history_save_path, 'wb') as f:\n",
    "    pickle.dump(history_helpdesk.history, f)\n",
    "\n",
    "print(f\"History saved to {history_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_save_path = '/home/lars.gsaenger/test/models/models_pretrained/histories/tuned_dynamic_bert_bpic2018_history.pkl'\n",
    "\n",
    "# Load the history object\n",
    "with open(history_save_path, 'rb') as f:\n",
    "    loaded_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model structure again for reloading weights\n",
    "\n",
    "class BERTModelBuilderDynamic():\n",
    "    def __init__(self, model_name, num_classes, batch_size, epochs):\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def create_model(self):\n",
    "\n",
    "        # Load the pretrained BERT model\n",
    "        encoder = TFAutoModel.from_pretrained(self.model_name)\n",
    "\n",
    "        # Input layer for input_ids and attention_masks\n",
    "        input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "        attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Get the pooled output and make sure it is of type tf.float32\n",
    "        pooled_output = tf.keras.layers.Lambda(lambda x: tf.cast(x.pooler_output, tf.float32))(encoder_outputs)\n",
    "\n",
    "        # Apply dropout\n",
    "        dropout = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n",
    "\n",
    "        # Final dense layer for classification with softmax activation function\n",
    "        output = tf.keras.layers.Dense(self.num_classes, activation='softmax', dtype=tf.float32)(dropout)\n",
    "        \n",
    "        # Create model\n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "        steps_per_epoch = int(len(train_tensor['Prefix_Trace'])/self.batch_size)\n",
    "        num_train_steps = steps_per_epoch * self.epochs\n",
    "        warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "        linear_decay = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=5e-05, decay_steps=num_train_steps, decay_rate=0.01)\n",
    "        optimizer = tfm.optimization.lr_schedule.LinearWarmup(warmup_learning_rate=0, after_warmup_lr_sched=linear_decay, warmup_steps=warmup_steps)\n",
    "\n",
    "        # Compile model with AdamW as optimzer\n",
    "        model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=optimizer),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "test = BERTModelBuilderDynamic(model_name='bert-base-uncased', num_classes=num_classes, batch_size=batch_size, epochs=epochs)\n",
    "test = test.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights into model\n",
    "\n",
    "weights_load_path = '/home/lars.gsaenger/test/models/Weights_BPIC2012_Tuned/Weights_BPIC2012_Tuned'\n",
    "test.load_weights(weights_load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if everything worked\n",
    "evaluation = test.evaluate(tf_test_dataset, steps=test_steps_per_epoch)\n",
    "\n",
    "print(f\"Validation loss: {evaluation[0]}\")\n",
    "print(f\"Validation accuracy: {evaluation[1]}\")\n",
    "\n",
    "# Make predictions on a test dataset (optional)\n",
    "predictions = test.predict(tf_test_dataset, steps=test_steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
